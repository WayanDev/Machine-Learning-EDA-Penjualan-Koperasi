{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Evaluation Results:\n",
      "                    Model            Training MSE  Training RMSE  Training R-squared  Training MAE  Training MAPE (%)\n",
      "         LinearRegression                    0.00           0.00                1.00          0.00               0.00\n",
      "                    Ridge    37138144408982192.00   192712595.36                0.96  174856073.29               2.45\n",
      "                    Lasso        9582443160399.08     3095552.16                1.00    2957665.80               0.04\n",
      "               ElasticNet    29244124357623144.00   171009135.30                0.97  162910288.95               2.27\n",
      "    DecisionTreeRegressor                    0.00           0.00                1.00          0.00               0.00\n",
      "    RandomForestRegressor    80851585859982416.00   284344132.80                0.92  238416210.71               3.47\n",
      "GradientBoostingRegressor            693562546.17       26335.58                1.00      21533.46               0.00\n",
      "                      SVR   998393211020278016.00   999196282.53               -0.02  793020289.82              11.48\n",
      "      KNeighborsRegressor   621171842111464320.00   788144556.61                0.37  702654214.29               9.86\n",
      "             MLPRegressor 56680075717715279872.00  7528617118.55              -56.66 7463042729.30             100.00\n",
      "\n",
      "Testing Set Evaluation Results:\n",
      "                    Model                Test MSE     Test RMSE  Test R-squared      Test MAE  Test MAPE (%)\n",
      "         LinearRegression   548344543476276672.00  740502899.03           -2.04  637654423.28           7.88\n",
      "                    Ridge    27040477649275676.00  164439890.69            0.85  159508895.80           2.04\n",
      "                    Lasso   521542819993443776.00  722179215.98           -1.89  616390863.36           7.64\n",
      "               ElasticNet    34883188667146636.00  186770417.00            0.81  159090974.33           2.08\n",
      "    DecisionTreeRegressor   398735843910353344.00  631455338.02           -1.21  506668866.67           6.61\n",
      "    RandomForestRegressor    12367511356964998.00  111209313.27            0.93   91834466.67           1.20\n",
      "GradientBoostingRegressor   133335398667078416.00  365151199.73            0.26  324706095.13           4.24\n",
      "                      SVR   255406982726213888.00  505378059.21           -0.42  433297998.64           5.37\n",
      "      KNeighborsRegressor   141755581717953328.00  376504424.57            0.21  303263133.33           3.72\n",
      "             MLPRegressor 61974558941700399104.00 7872392199.43         -342.77 7860933790.41         100.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "\n",
    "# Establish database connection\n",
    "db_connection = mysql.connector.connect(\n",
    "    host=\"localhost\",  \n",
    "    user=\"root\",       \n",
    "    password=\"\",       \n",
    "    database=\"jurujual_pos\"  \n",
    ")\n",
    "\n",
    "def remove_outliers(df, col_name):\n",
    "    Q1 = df[col_name].quantile(0.25)\n",
    "    Q3 = df[col_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    df_no_outliers = df[(df[col_name] >= lower_bound) & (df[col_name] <= upper_bound)]\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "# SQL query to fetch data\n",
    "query = \"\"\"\n",
    "SELECT s.date AS Tanggal, s.reference AS Reference, s.customer_name AS Pembeli, \n",
    "    p.product_unit AS Satuan, p.product_name AS Produk, c.category_name AS Kategori,\n",
    "    sd.quantity AS Qty, p.product_price AS HargaJual, sd.product_discount_amount AS Diskon,\n",
    "    sp.amount AS SubTotal, s.payment_method AS MetodePembayaran, \n",
    "    s.status AS Status, s.payment_status AS StatusPembayaran\n",
    "    \n",
    "FROM sales s\n",
    "JOIN sale_details sd ON s.id = sd.sale_id\n",
    "JOIN sale_payments sp ON s.id = sp.sale_id\n",
    "JOIN products p ON sd.product_id = p.id\n",
    "JOIN categories c ON p.category_id = c.id;\n",
    "\"\"\"\n",
    "\n",
    "# Reading data into a DataFrame\n",
    "df = pd.read_sql(query, con=db_connection)\n",
    "db_connection.close()\n",
    "\n",
    "# Preprocessing the date column and adding month and year columns\n",
    "df['Tanggal'] = pd.to_datetime(df['Tanggal'])\n",
    "df['Bulan'] = df['Tanggal'].dt.month\n",
    "df['Tahun'] = df['Tanggal'].dt.year\n",
    "\n",
    "monthly_sales = df.groupby(['Tahun', 'Bulan']).agg({\n",
    "    'SubTotal': 'sum',\n",
    "    'Produk': 'nunique',  \n",
    "    'Reference': 'nunique',\n",
    "    'Pembeli': 'nunique',\n",
    "    'Satuan': 'nunique',\n",
    "    'Kategori': 'nunique',\n",
    "    'MetodePembayaran': 'nunique',\n",
    "    'Qty': 'sum',\n",
    "    'HargaJual': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Encoding categorical features\n",
    "le = LabelEncoder()\n",
    "for col in monthly_sales.columns:\n",
    "    if monthly_sales[col].dtype == 'object':\n",
    "        monthly_sales[col] = le.fit_transform(monthly_sales[col])\n",
    "\n",
    "columns_with_outliers = ['SubTotal']\n",
    "for col in columns_with_outliers:\n",
    "    monthly_sales = remove_outliers(monthly_sales, col)\n",
    "\n",
    "# Defining features (X) and target (y)\n",
    "X = monthly_sales[['Reference','Pembeli','Produk', 'Kategori', 'Qty', 'HargaJual', 'Bulan']]\n",
    "y = monthly_sales['SubTotal']\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Function to evaluate and return model performance as DataFrame\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    train_rmse = round(train_mse ** 0.5, 2)\n",
    "    train_r2 = round(r2_score(y_train, y_train_pred), 2)\n",
    "    train_mae = round(mean_absolute_error(y_train, y_train_pred), 2)\n",
    "    train_mape = round(np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100, 2)\n",
    "    \n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_rmse = round(test_mse ** 0.5, 2)\n",
    "    test_r2 = round(r2_score(y_test, y_test_pred), 2)\n",
    "    test_mae = round(mean_absolute_error(y_test, y_test_pred), 2)\n",
    "    test_mape = round(np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100, 2)\n",
    "    \n",
    "    model_name = model.__class__.__name__\n",
    "    performance_dict_train = {\n",
    "        'Model': model_name,\n",
    "        'Training MSE': train_mse,\n",
    "        'Training RMSE': train_rmse,\n",
    "        'Training R-squared': train_r2,\n",
    "        'Training MAE': train_mae,\n",
    "        'Training MAPE (%)': train_mape\n",
    "    }\n",
    "    \n",
    "    performance_dict_test = {\n",
    "        'Model': model_name,\n",
    "        'Test MSE': test_mse,\n",
    "        'Test RMSE': test_rmse,\n",
    "        'Test R-squared': test_r2,\n",
    "        'Test MAE': test_mae,\n",
    "        'Test MAPE (%)': test_mape\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(performance_dict_train, index=[0]), pd.DataFrame(performance_dict_test, index=[0])\n",
    "\n",
    "# Initialize empty DataFrames for training and testing results\n",
    "results_df_train = pd.DataFrame()\n",
    "results_df_test = pd.DataFrame()\n",
    "\n",
    "# Models to evaluate\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=0.1),\n",
    "    ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1),\n",
    "    KNeighborsRegressor(n_neighbors=5),\n",
    "    MLPRegressor(hidden_layer_sizes=(100,100), max_iter=500, random_state=42)\n",
    "]\n",
    "\n",
    "# Evaluate each model and append results to respective DataFrames\n",
    "for model in models:\n",
    "    model_results_train, model_results_test = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "    results_df_train = pd.concat([results_df_train, model_results_train], axis=0)\n",
    "    results_df_test = pd.concat([results_df_test, model_results_test], axis=0)\n",
    "\n",
    "# Reset index of results DataFrames\n",
    "results_df_train.reset_index(drop=True, inplace=True)\n",
    "results_df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the results DataFrames with 2 decimal places\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "print(\"Training Set Evaluation Results:\")\n",
    "print(results_df_train.to_string(index=False))\n",
    "\n",
    "print(\"\\nTesting Set Evaluation Results:\")\n",
    "print(results_df_test.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
